{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GnZdaTi6FgHf"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MedicDoesStuff/RVC-Disconnected/blob/main/RVC_Disconnected_(V2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔴 **RVC - Disconnected** 🔴\n",
        "\n",
        "***Modified by [MedicDoesStuff](https://www.youtube.com/@medicdoesstuff/)***\n",
        "\n",
        "**Notebook hastily written by [Kit Lemonfoot](https://huggingface.co/Kit-Lemonfoot) / [Noel Shirogane's High Flying Birds](https://www.youtube.com/@NoelShiroganesHighFlyingBirds)**\n",
        "\n",
        "*Based on the work of the [RVC Project](https://github.com/RVC-Project), [Mangio261](https://github.com/Mangio621/), [Kalomaze](https://github.com/kalomaze), [Alexlnkp](https://github.com/alexlnkp), the [Pony Preservation Project](https://boards.4channel.org/mlp/catalog#s=Pony%20Preservation%20Project), and many others in the RVC / voice AI community* ❤\n",
        "\n",
        "*Notebook version:* **0.24**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is designed to be used with training Retreival-Based Voice Conversion (RVC) models without using a WеbUl. This is done to stay within the scope of Colab's TOS.\n",
        "\n",
        "⚠️ WARNING: Unlike the original RVC notebook, *this notebook ***does not*** have autosave functionality* due to the massive amount of underlying stress that RVC's autosave features places on Colab to Drive communication. Please be careful and try to keep training sessions short."
      ],
      "metadata": {
        "id": "FrR4hoSR50Wt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dependencies**\n",
        "🟢 Run this first!"
      ],
      "metadata": {
        "id": "GnZdaTi6FgHf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBpJW3YB5zu1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install Dependencies\n",
        "import subprocess\n",
        "\n",
        "packages = ['build-essential', 'python3-dev', 'ffmpeg', 'aria2']\n",
        "pip_packages = ['pip', 'setuptools', 'wheel', 'faiss-gpu', 'fairseq', 'ffmpeg', 'ffmpeg-python', 'praat-parselmouth', 'pyworld', 'numpy==1.23.5', 'numba==0.56.4', 'librosa==0.9.2']\n",
        "print(\"Updating and installing system packages...\")\n",
        "for package in packages:\n",
        "  print(f\"Installing {package}...\")\n",
        "  subprocess.check_call(['apt-get', 'install', '-qq', '-y', package])\n",
        "\n",
        "print(\"Updating and installing pip packages...\")\n",
        "subprocess.check_call(['pip', 'install', '--upgrade'] + pip_packages)\n",
        "\n",
        "print('Packages up to date.')\n",
        "firsttry = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Repositories\n",
        "import os\n",
        "\n",
        "# READ ME BEFORE CHANGING THINGS\n",
        "# If you're attempting to replace the imports here with Applio-RVC, it will not work due to requirement discrepancies across the entire notebook.\n",
        "# I will not be porting this notebook to Applio due to the failure of the Applio team to provide backwards compatibility with the Crepe and Mangio-Crepe f0 feature format.\n",
        "# DO NOT ASK. IT WILL NOT HAPPEN.\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "if(os.path.exists(\"/content/Mangio-RVC-Fork\")):\n",
        "  print(\"RVC already installed, skipping.\")\n",
        "else:\n",
        "  #Credit to miaaaa0a on the AI Hub Discord for (indirectly) suggesting this variant of Mangio RVC to me.\n",
        "  !git clone -b pr-optimization --single-branch https://github.com/alexlnkp/Mangio-RVC-Tweaks.git\n",
        "  #Rename to keep backwards compatibility with old variants of Disconnected\n",
        "  os.rename(\"/content/Mangio-RVC-Tweaks\", \"/content/Mangio-RVC-Fork\")\n",
        "  !git clone https://github.com/maxrmorrison/torchcrepe.git\n",
        "  !mv torchcrepe/torchcrepe Mangio-RVC-Fork/\n",
        "  !rm -rf torchcrepe  # Delete the torchcrepe repository folder\n",
        "\n",
        "os.chdir('/content/Mangio-RVC-Fork')\n",
        "now_dir = \"/content/Mangio-RVC-Fork\"\n",
        "os.makedirs(os.path.join(now_dir, \"logs\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(now_dir, \"weights\"), exist_ok=True)"
      ],
      "metadata": {
        "id": "McbFvkWfJQCO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GPU Check\n",
        "import torch\n",
        "\n",
        "ngpu = torch.cuda.device_count()\n",
        "gpu_infos = []\n",
        "mem = []\n",
        "if_gpu_ok = False\n",
        "\n",
        "if torch.cuda.is_available() or ngpu != 0:\n",
        "  for i in range(ngpu):\n",
        "    gpu_name = torch.cuda.get_device_name(i)\n",
        "    if any(\n",
        "        value in gpu_name.upper()\n",
        "        for value in [\"10\", \"16\", \"20\", \"30\", \"40\", \"A2\", \"A3\", \"A4\", \"P4\", \"A50\", \"500\", \"A60\", \"70\", \"80\", \"90\", \"M4\", \"T4\", \"TITAN\"]\n",
        "    ):\n",
        "      if_gpu_ok = True\n",
        "      print(\"Compatible GPU detected: %s\" % gpu_name)\n",
        "      gpu_infos.append(\"%s\\t%s\" % (i, gpu_name))\n",
        "      mem.append(int(torch.cuda.get_device_properties(i).total_memory / 1024 / 1024 / 1024 + 0.4))\n",
        "\n",
        "if if_gpu_ok and len(gpu_infos) > 0:\n",
        "  gpu_info = \"\\n\".join(gpu_infos)\n",
        "\n",
        "else:\n",
        "  raise Exception(\"No GPU detected; training cannot continue. Please change your runtime type to a GPU.\")\n",
        "gpus = \"-\".join(i[0] for i in gpu_infos)"
      ],
      "metadata": {
        "id": "E4W8p1ZLLXLy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Drive\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print('Drive is already mounted. Proceed.')\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/RVC-Disconnected', exist_ok=True)"
      ],
      "metadata": {
        "id": "1i1eYRMYfE79",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Pretrained Models\n",
        "#Didn't ask.\n",
        "\n",
        "#V1\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0G32k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0D32k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0G40k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0D40k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0G48k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0D48k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0D48k.pth\n",
        "\n",
        "#V2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G32k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D32k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G40k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D40k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G48k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D48k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D48k.pth\n",
        "\n",
        "#OV2 pretrains\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/f0Ov2Super32kG.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G32k_OV2.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/f0Ov2Super32kD.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D32k_OV2.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super40kG.pth?download=true -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G40k_OV2.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super40kD.pth?download=true -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D40k_OV2.pth\n",
        "#TEMP UNTIL NEW PRETRAINS ARE OUT\n",
        "#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G48k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G48k_OV2.pth\n",
        "#!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D48k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D48k_OV2.pth\n",
        "\n",
        "#RIN_E3 pretrains\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/MUSTAR/RIN_E3/resolve/main/RIN_E3_G.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G40k_RIN_E3.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/MUSTAR/RIN_E3/resolve/main/RIN_E3_D.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D40k_RIN_E3.pth\n",
        "\n",
        "#Hubert/RMVPE\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/hubert_base.pt -d /content/Mangio-RVC-Fork -o hubert_base.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/rmvpe.pt -d /content/Mangio-RVC-Fork -o rmvpe.pt\n",
        "\n",
        "#FM JSONs\n",
        "!rm -rf /content/Mangio-RVC-Fork/configs/32k.json\n",
        "!rm -rf /content/Mangio-RVC-Fork/configs/40k.json\n",
        "!rm -rf /content/Mangio-RVC-Fork/configs/48k.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/32k.json -d /content/Mangio-RVC-Fork/configs -o 32k.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/40k.json -d /content/Mangio-RVC-Fork/configs -o 40k.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/48k.json -d /content/Mangio-RVC-Fork/configs -o 48k.json"
      ],
      "metadata": {
        "id": "v_zQGeguKD5s",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup CSVDB\n",
        "#...Alright, you made your point.\n",
        "import csv\n",
        "\n",
        "if not os.path.isdir(\"csvdb/\"):\n",
        "  os.makedirs(\"csvdb\")\n",
        "  frmnt, stp = open(\"csvdb/formanting.csv\", \"w\", newline=\"\"), open(\"csvdb/stop.csv\", \"w\", newline=\"\")\n",
        "  csv_writer = csv.writer(frmnt, delimiter=\",\")\n",
        "  csv_writer.writerow([False, 1.0, 1.0])\n",
        "  csv_writer = csv.writer(stp, delimiter=\",\")\n",
        "  csv_writer.writerow([False])\n",
        "  frmnt.close()\n",
        "  stp.close()\n",
        "\n",
        "global DoFormant, Quefrency, Timbre\n",
        "DoFormant, Quefrency, Timbre = False, 1.0, 1.0"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0LGNhYjGaBBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set Training Variables**\n",
        "\n",
        "- `experiment_name`: The name of the model. (i.e: EminemMMLP2)\n",
        "- `pretrain_type`: Choose whether to use the original, OV2, or the RIN_E3.\n",
        "- `model_architecture`: Specifies the chosen model version. V2 is recommended.\n",
        "- `target_sample_rate`: Specifies the desired sample rate for the model, The new 40K is recommended for general training.\n",
        "- `cpu_threads`: Specifies the number of CPU threads to be used during the training. Colab only has 2 so don't even bother changing it.\n",
        "- `speaker_id`: Represents the ID of the speaker being trained, I recommend not changing it.\n",
        "- `pitch_extraction_algorithm`: Specifies the algorithm used for pitch extraction from the audio data, rmvpe is recommended.\n",
        "- `crepe_hop_length`: Represents the hop length parameter used in the Crepe algorithm for pitch extraction, only affects crepe and mangio-crepe.\n",
        "- `pitch_guidance`: Indicates whether pitch guidance is enabled or disabled for the experiment, can be useful if you want a talking or singing model."
      ],
      "metadata": {
        "id": "oi6yLWNM31rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set Training Variables\n",
        "now_dir = \"/content/Mangio-RVC-Fork\"\n",
        "experiment_name = \"experiment_name\" #@param {type:\"string\"}\n",
        "pretrain_type = \"OV2\" #@param [\"original\", \"OV2\", \"RIN_E3\"] {allow-input: false}\n",
        "path_to_training_folder = \"/content/dataset/\"\n",
        "model_architecture = \"v2\" #@param [\"v1\",\"v2\"] {allow-input: false}\n",
        "target_sample_rate = \"40k\" #@param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n",
        "#cpu_threads = 2 #@param {type:\"integer\"}\n",
        "speaker_id = 0 #@param {type:\"integer\"}\n",
        "pitch_extraction_algorithm = \"rmvpe\" #@param [\"harvest\", \"crepe\", \"mangio-crepe\", \"rmvpe\"] {allow-input: false}\n",
        "crepe_hop_length = 64 #@param {type:\"integer\"}\n",
        "pitch_guidance = True #@param {type:\"boolean\"}\n",
        "\n",
        "cpu_threads = !nproc\n",
        "cpu_threads = int(cpu_threads[0])\n",
        "\n",
        "exp_dir = f\"{now_dir}/logs/{experiment_name}\"\n",
        "\n",
        "assert crepe_hop_length!=None, \"You need to input something for crepe_hop_length, silly.\"\n",
        "assert crepe_hop_length>0, \"Hop length must be more than 0.\"\n",
        "assert crepe_hop_length<=512, \"Save frequency must be less than 512.\"\n",
        "\n",
        "if pretrain_type!=\"original\" and model_architecture!=\"v2\":\n",
        "  model_architecture=\"v2\"\n",
        "  print(\"The new pretrains only support RVC v2 at this time. Your settings have been automatically adjusted.\")\n",
        "\n",
        "#TEMPORARY UNTIL SIMPLCUP 48K IS RELEASED\n",
        "if pretrain_type!=\"original\" and target_sample_rate==\"48k\":\n",
        "  target_sample_rate=\"40k\"\n",
        "  print(\"The new pretrains only support 40k sample rate and lower at this time. Your settings have been automatically adjusted.\")\n",
        "if pretrain_type==\"RIN_E3\" and target_sample_rate!=\"40k\":\n",
        "  target_sample_rate=\"40k\"\n",
        "  print(\"RIN_E3 only supports 40k sample rate at this time. Your settings have been automatically adjusted.\")\n",
        "\n",
        "\n",
        "if(experiment_name == \"experiment_name\"):\n",
        "  print(\"Warning: Your experiment name should be changed to the name of your dataset.\")"
      ],
      "metadata": {
        "id": "ZodNcumpg-JM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing**\n",
        "🟢 You should only need to run these cells once per model."
      ],
      "metadata": {
        "id": "GpjFLdlRFlcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset\n",
        "#@markdown If it doesn't already exist, create a folder in your Google Drive named 'RVC-Disconnected' and place your zip file there. This will look for the following ZIP file inside that 'RVC-Disconnected' folder.\n",
        "dataset = \"zipfile.zip\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown This loader will load datasets in a similar fashion to the SVC dataset loader. For best results, your dataset should be formatted as such:\n",
        "#@markdown ```\n",
        "#@markdown zipfile.zip\n",
        "#@markdown └───character_name\n",
        "#@markdown     ├───data.wav\n",
        "#@markdown ```\n",
        "#@markdown Audio filenames do not matter. All audio files should be in WAV format for best compatibility.\n",
        "\n",
        "#@markdown You do not need to split the WAV files, preprocessing will automatically do it for you.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "directories=[]\n",
        "\n",
        "def sanitize_directory(directory):\n",
        "  for filename in os.listdir(directory):\n",
        "    file_path = os.path.join(directory, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "      if filename == \".DS_Store\" or filename.startswith(\"._\") or not filename.endswith(('.wav', '.flac', '.mp3', '.ogg', '.m4a')):\n",
        "        os.remove(file_path)\n",
        "    elif os.path.isdir(file_path):\n",
        "      #Get rid of the MACOSX directory just so it doesn't mess with renaming later\n",
        "      if(filename == \"__MACOSX\"):\n",
        "        shutil.rmtree(file_path)\n",
        "        continue\n",
        "      #Append the directory to directories for future dataset check, then recurse.\n",
        "      directories.append(file_path)\n",
        "      sanitize_directory(file_path)\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/RVC-Disconnected/' + dataset\n",
        "final_directory = '/content/dataset'\n",
        "temp_directory = '/content/temp_dataset'\n",
        "\n",
        "if os.path.exists(final_directory):\n",
        "  print(\"Dataset folder already found. Wiping...\")\n",
        "  shutil.rmtree(final_directory)\n",
        "if os.path.exists(temp_directory):\n",
        "  print(\"Temporary folder already found. Wiping...\")\n",
        "  shutil.rmtree(temp_directory)\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "  raise Exception(f'I can\\'t find {dataset} in {os.path.dirname(dataset_path)}.')\n",
        "\n",
        "os.makedirs(final_directory, exist_ok=True)\n",
        "os.makedirs(temp_directory, exist_ok=True)\n",
        "#Oops.\n",
        "!unzip -d \"{temp_directory}\" -B \"{dataset_path}\"\n",
        "print(\"Sanitizing...\")\n",
        "sanitize_directory(temp_directory)\n",
        "\n",
        "if(len(directories) == 0):\n",
        "  #If there's no directories, we're dealing with a ZIP of just audio files.\n",
        "  #Move everything to /dataset/experiment_name/.\n",
        "  print(\"Dataset Type: Audio Files (Single Speaker)\")\n",
        "  expDir=os.path.join(final_directory, experiment_name)\n",
        "  os.makedirs(expDir, exist_ok=True)\n",
        "  for r, _, f in os.walk(temp_directory):\n",
        "    for name in f:\n",
        "      !cp \"{temp_directory}/{name}\" \"{expDir}\"\n",
        "elif(len(directories) == 1):\n",
        "  #If there's only one directory, we're dealing with a single speaker.\n",
        "  #Rename the folder to experiment_name and move it to /dataset/.\n",
        "  print(\"Dataset Type: Single Speaker\")\n",
        "  fi = os.path.join(temp_directory, experiment_name)\n",
        "  os.rename(directories[0], fi)\n",
        "  shutil.move(fi, final_directory)\n",
        "\n",
        "else:\n",
        "  #If anything else, we're dealing with multispeaker.\n",
        "  #Move all folders to /dataset/ indiscriminately.\n",
        "  print(\"Dataset Type: Multispeaker\")\n",
        "  for fi in directories:\n",
        "    shutil.move(fi, final_directory)\n",
        "\n",
        "shutil.rmtree(temp_directory)\n",
        "\n",
        "print(\"Dataset imported.\")\n"
      ],
      "metadata": {
        "id": "g1X5oANker6l",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocessing\n",
        "# Change the experiment Name and the path to the training folder. You shouldn't need to change anything else.\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "assert cpu_threads>0, \"CPU threads not allocated correctly.\"\n",
        "\n",
        "sr = int(target_sample_rate.rstrip('k'))*1000\n",
        "pttf = path_to_training_folder + experiment_name\n",
        "os.makedirs(\"%s/logs/%s\" % (now_dir, experiment_name), exist_ok=True)\n",
        "\n",
        "cmd = \"python trainset_preprocess_pipeline_print.py \\\"%s\\\" %s %s \\\"%s/logs/%s\\\" 1\" % (pttf, sr, cpu_threads, now_dir, experiment_name)\n",
        "print(cmd)\n",
        "!$cmd"
      ],
      "metadata": {
        "id": "OPNzuVYG7N_R",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature extraction\n",
        "\n",
        "pitch_extraction_algorithm = \"rmvpe\" #@param [\"harvest\", \"crepe\", \"mangio-crepe\", \"rmvpe\"] {allow-input: false}\n",
        "#crepe_hop_length = 128 #@param {type:\"slider\", min:1, max:512, step:1}\n",
        "#pitch_guidance = True #@param {type:\"boolean\"}\n",
        "\n",
        "gpuList = gpus.split(\"-\")\n",
        "cmd = \"python extract_f0_print.py \\\"%s/logs/%s\\\" %s %s %s\" % (now_dir, experiment_name, cpu_threads, pitch_extraction_algorithm, crepe_hop_length)\n",
        "print(cmd)\n",
        "!$cmd\n",
        "\n",
        "leng = len(gpus)\n",
        "\n",
        "cmd = \"python extract_feature_print.py %s %s %s %s \\\"%s/logs/%s\\\" %s\" % (\"device\", leng, 0, 0, now_dir, experiment_name, model_architecture)\n",
        "print(cmd)\n",
        "!$cmd\n"
      ],
      "metadata": {
        "id": "u6iN6C-U94DS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save preprocessed dataset files to Google Drive\n",
        "#Compress dataset folder\n",
        "loc = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
        "!zip -r rvcLogs.zip \"{loc}\"\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/RVC-Disconnected/\" + experiment_name\n",
        "!mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "!cp /content/Mangio-RVC-Fork/rvcLogs.zip \"{DATASET_PATH_DRIVE}\""
      ],
      "metadata": {
        "id": "y959_sq7kToW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**\n",
        "🟢 Also includes resuming code."
      ],
      "metadata": {
        "id": "vjcmh9u_MweU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load preprocessed dataset files from Google Drive (for resuming)\n",
        "#@markdown If you already have preprocessed dataset files on Google Drive, you can load them here instead of re-running the preprocessing steps.\n",
        "import os\n",
        "\n",
        "BACK_UP_DATASET_PATH = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "\n",
        "#Prevent people from loading the ZIP over existing files\n",
        "ok=True\n",
        "if(os.path.exists(\"/content/Mangio-RVC-Fork/logs/\"+experiment_name+\"/2a_f0\")):\n",
        "  print(\"Dataset files already loaded, skipping.\")\n",
        "  ok=False\n",
        "\n",
        "if ok:\n",
        "  !unzip \"{BACK_UP_DATASET_PATH}/rvcLogs.zip\" -d /"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_BkhWhrCMdgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Model from Drive to Notebook (for resuming)\n",
        "import os\n",
        "\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "#@markdown Input the model's Step Count here (the number located on your model's G and D files.) If you used `save_only_last_ckpt` during training, this number will be 2333333.\n",
        "STEPCOUNT = 2333333 #@param {type:\"integer\"}\n",
        "\n",
        "print(\"Copying model files...\")\n",
        "!cp \"{DATASET_PATH_DRIVE}/D_{STEPCOUNT}.pth\" \"{DATASET_PATH_COLAB}\"\n",
        "!cp \"{DATASET_PATH_DRIVE}/G_{STEPCOUNT}.pth\" \"{DATASET_PATH_COLAB}\"\n",
        "!cp \"{DATASET_PATH_DRIVE}/config.json\" \"{DATASET_PATH_COLAB}\"\n",
        "\n",
        "print(\"Copying Tensorboard TFEVENT files...\")\n",
        "for r, _, f in os.walk(DATASET_PATH_DRIVE):\n",
        "  for name in f:\n",
        "    if(name.startswith(\"events.out.tfevents\")):\n",
        "      !cp \"{DATASET_PATH_DRIVE}/{name}\" \"{DATASET_PATH_COLAB}\"\n",
        "\n",
        "print(\"All done. Welcome back!\")"
      ],
      "metadata": {
        "id": "JbmAq_mZ7Zuh",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from random import shuffle\n",
        "\n",
        "#@title Training\n",
        "save_frequency = 50 #@param {type:\"integer\"}\n",
        "total_epochs = 300 #@param {type:\"integer\"}\n",
        "batch_size = 16 #@param {type:\"integer\"}\n",
        "save_only_latest_ckpt = True #@param {type:\"boolean\"}\n",
        "cache_all_training_sets = False #@param {type:\"boolean\"}\n",
        "save_small_final_model = True #@param {type:\"boolean\"}\n",
        "#@markdown The automatically calculated log interval is known to be very inaccurate and can cause delays between an epoch finishing and Tensorboard writes. If you would like, you can manually define a log interval here.\n",
        "use_manual_stepToEpoch = False #@param {type:\"boolean\"}\n",
        "manual_stepToEpoch = 000 #@param {type:\"integer\"}\n",
        "\n",
        "assert save_frequency!=None, \"You need to input something for save_frequency, silly.\"\n",
        "assert save_frequency>0, \"Save frequency must be more than 0.\"\n",
        "if(save_frequency>50):print(f\"...A save frequency of {save_frequency}? A bit high, but... alright then.\")\n",
        "assert total_epochs!=None, \"You need to input something for total_epochs, silly.\"\n",
        "assert total_epochs>0, \"Total epochs must be more than 0.\"\n",
        "if(total_epochs>10000):print(f\"...A total epoch count of of {total_epochs}? This is going to overtrain, but... alright then.\")\n",
        "assert batch_size!=None, \"You need to input something for batch_size, silly.\"\n",
        "assert batch_size>0, \"Batch size must be more than 0.\"\n",
        "assert batch_size<=40, \"Batch size must be less than 40. (I'd reccomend a value between 6 and 12 for Colab.)\"\n",
        "\n",
        "pretrained_base = \"pretrained/\" if model_architecture == \"v1\" else \"pretrained_v2/\"\n",
        "unpt = f\"_{pretrain_type}\" if pretrain_type!=\"original\" else \"\"\n",
        "\n",
        "pretrainedD = f\"{pretrained_base}f0D{target_sample_rate}{unpt}.pth\"\n",
        "pretrainedG = f\"{pretrained_base}f0G{target_sample_rate}{unpt}.pth\"\n",
        "\n",
        "#Log interval\n",
        "log_interval = 1\n",
        "liFolderPath = os.path.join(exp_dir, \"1_16k_wavs\")\n",
        "if(os.path.exists(liFolderPath) and os.path.isdir(liFolderPath)):\n",
        "  wav_files = [f for f in os.listdir(liFolderPath) if f.endswith(\".wav\")]\n",
        "  if wav_files:\n",
        "    sample_size = len(wav_files)\n",
        "    log_interval = math.ceil(sample_size / batch_size)\n",
        "    if log_interval > 1:\n",
        "      log_interval += 1\n",
        "\n",
        "if log_interval > 250 and not use_manual_stepToEpoch:\n",
        "  print(f\"That's a big dataset you got there. Log interval normalized to 200 steps from {log_interval} steps.\")\n",
        "  log_interval = 200\n",
        "\n",
        "if use_manual_stepToEpoch:\n",
        "  log_interval = manual_stepToEpoch\n",
        "\n",
        "#Create Python command\n",
        "cmd = \"python train_nsf_sim_cache_sid_load_pretrain.py -e \\\"%s\\\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s -li %s\" % (\n",
        "    experiment_name,\n",
        "    target_sample_rate,\n",
        "    1,\n",
        "    batch_size,\n",
        "    0,\n",
        "    total_epochs,\n",
        "    save_frequency,\n",
        "    \"-pg %s\" % pretrainedG if pretrainedG != \"\" else \"\\b\",\n",
        "    \"-pd %s\" % pretrainedD if pretrainedD != \"\" else \"\\b\",\n",
        "    1 if save_only_latest_ckpt else 0,\n",
        "    1 if cache_all_training_sets else 0,\n",
        "    1 if save_small_final_model else 0,\n",
        "    model_architecture,\n",
        "    log_interval,\n",
        ")\n",
        "print(cmd)\n",
        "\n",
        "#Create mute filelist\n",
        "gt_wavs_dir = f\"{exp_dir}/0_gt_wavs\"\n",
        "feature_dir = (\n",
        "  f\"{exp_dir}/3_feature256\"\n",
        "  if model_architecture == \"v1\"\n",
        "  else f\"{exp_dir}/3_feature768\"\n",
        ")\n",
        "f0_dir = f\"{exp_dir}/2a_f0\"\n",
        "f0nsf_dir = f\"{exp_dir}/2b-f0nsf\"\n",
        "names = (\n",
        "  set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        ")\n",
        "opt = []\n",
        "for name in names:\n",
        "  opt.append(\n",
        "    \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "    % (\n",
        "      gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      speaker_id,\n",
        "    )\n",
        "  )\n",
        "fea_dim = 256 if model_architecture == \"v1\" else 768\n",
        "for _ in range(2):\n",
        "  opt.append(\n",
        "      f\"{now_dir}/logs/mute/0_gt_wavs/mute{target_sample_rate}.wav|{now_dir}/logs/mute/3_feature{fea_dim}/mute.npy|{now_dir}/logs/mute/2a_f0/mute.wav.npy|{now_dir}/logs/mute/2b-f0nsf/mute.wav.npy|{speaker_id}\"\n",
        "  )\n",
        "shuffle(opt)\n",
        "with open(f\"{exp_dir}/filelist.txt\", \"w\") as f:\n",
        "  f.write(\"\\n\".join(opt))\n",
        "print(\"Mute filelist written. Best of luck training!\")\n",
        "\n",
        "\n",
        "%cd /content/Mangio-RVC-Fork\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/Mangio-RVC-Fork/logs\n",
        "\n",
        "os.chdir('/content/Mangio-RVC-Fork')\n",
        "!$cmd\n"
      ],
      "metadata": {
        "id": "Yj-_npuA_HRB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Index Training\n",
        "#@markdown Ensure that Feature Extraction has run successfully before running this cell.\n",
        "\n",
        "#@markdown **Note: It's rare, but you may encounter a bug with this cell that requires a runtime restart.**\n",
        "#@markdown **If this happens, restart the runtime, re-run the \"Set Training Variables\" cell, then re-run this cell.**\n",
        "\n",
        "#@markdown Use this option if you wish to save the two extra files generated by index training to your Google Drive. (Only the added index is normally needed.)\n",
        "save_extra_files_to_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "#Oh dear lord why is this baked into infer-web I hate this\n",
        "import os\n",
        "import sys\n",
        "import traceback\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "#from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "exp_dir = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
        "os.makedirs(exp_dir, exist_ok=True)\n",
        "feature_dir = (\n",
        "    \"%s/3_feature256\" % (exp_dir)\n",
        "    if model_architecture == \"v1\"\n",
        "    else \"%s/3_feature768\" % (exp_dir)\n",
        ")\n",
        "print(feature_dir)\n",
        "if not os.path.exists(feature_dir):\n",
        "  raise Exception(\"No features exist for this model yet. Did you run Feature Extraction?\")\n",
        "listdir_res = list(os.listdir(feature_dir))\n",
        "if len(listdir_res) == 0:\n",
        "  raise Exception(\"No features exist for this model yet. Did you run Feature Extraction?\")\n",
        "\n",
        "try:\n",
        "  from sklearn.cluster import MiniBatchKMeans\n",
        "except:\n",
        "  print(\"Due to a bug with Colab, we will need to reinstall Numpy real quick. Give me a sec!\")\n",
        "  !pip install -U numpy\n",
        "  print(\"Numpy reinstalled. Please restart the runtime, and then re-run the \\\"Set Training Variables\\\" cell to continue.\")\n",
        "  sys.exit()\n",
        "else:\n",
        "  print(\"Proper Numpy version detected.\")\n",
        "\n",
        "infos=[]\n",
        "npys=[]\n",
        "for name in sorted(listdir_res):\n",
        "  phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
        "  npys.append(phone)\n",
        "big_npy = np.concatenate(npys, 0)\n",
        "big_npy_idx = np.arange(big_npy.shape[0])\n",
        "np.random.shuffle(big_npy_idx)\n",
        "if big_npy.shape[0] > 2e5:\n",
        "  print(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
        "  try:\n",
        "    big_npy = (\n",
        "        MiniBatchKMeans(\n",
        "            n_clusters=10000,\n",
        "            verbose=True,\n",
        "            batch_size=256,\n",
        "            compute_labels = False,\n",
        "            init=\"random\"\n",
        "        )\n",
        "        .fit(big_npy)\n",
        "        .cluster_centers_\n",
        "\n",
        "    )\n",
        "  except:\n",
        "    info = traceback.format_exc()\n",
        "    print(info)\n",
        "\n",
        "np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
        "n_ivf = min(int(16*np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "print(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
        "index = faiss.index_factory(256 if model_architecture == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
        "print(\"Training index...\")\n",
        "index_ivf = faiss.extract_index_ivf(index)\n",
        "index_ivf.nprobe = 1\n",
        "index.train(big_npy)\n",
        "faiss.write_index(\n",
        "    index,\n",
        "    \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\" % (exp_dir, n_ivf, index_ivf.nprobe, experiment_name, model_architecture)\n",
        ")\n",
        "print(\"Adding...\")\n",
        "batch_size_add = 8192\n",
        "for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "  index.add(big_npy[i:i+batch_size_add])\n",
        "faiss.write_index(\n",
        "    index,\n",
        "    \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "    % (exp_dir, n_ivf, index_ivf.nprobe, experiment_name, model_architecture)\n",
        ")\n",
        "\n",
        "npr = index_ivf.nprobe\n",
        "\n",
        "print(\"Saving files to Drive...\")\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/RVC-Disconnected/\" + experiment_name\n",
        "if(not os.path.exists(DATASET_PATH_DRIVE)):\n",
        "  !mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "if(save_extra_files_to_drive):\n",
        "  !cp \"{DATASET_PATH_COLAB}/total_fea.npy\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/trained_IVF{n_ivf}_Flat_nprobe_{npr}_{experiment_name}_{model_architecture}.index\" \"{DATASET_PATH_DRIVE}\"\n",
        "!cp \"{DATASET_PATH_COLAB}/added_IVF{n_ivf}_Flat_nprobe_{npr}_{experiment_name}_{model_architecture}.index\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"All done! Your index file has completed training.\")\n",
        "try:\n",
        "  firsttry\n",
        "except:\n",
        "  print(\"If you had to restart the runtime, disconnect and delete the runtime in order to continue. (Restarting the runtime again will not work.)\")\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9mI_m7vfimC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Export Model from Notebook to Drive\n",
        "import os\n",
        "\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/RVC-Disconnected/\" + experiment_name\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "if(not os.path.exists(DATASET_PATH_DRIVE)):\n",
        "  !mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "#@markdown Use this option if you wish to only copy over weights.\n",
        "skip_models = False #@param {type:\"boolean\"}\n",
        "#@markdown Use these options if you wish to manually input your step count and epoch count for incomplete models. *Do not use this option if your training finished.*\n",
        "manual_save = False #@param {type:\"boolean\"}\n",
        "STEPCOUNT = 000 #@param {type:\"integer\"}\n",
        "EPOCHCOUNT = 000 #@param {type:\"integer\"}\n",
        "\n",
        "finished=False\n",
        "potential=\"/content/Mangio-RVC-Fork/weights/\"+experiment_name+\".pth\"\n",
        "if os.path.exists(potential):\n",
        "  finished = True\n",
        "\n",
        "#VERY hacky. Might break stuff, report to me if it does.\n",
        "print(\"Detecting latest model...\")\n",
        "if(not manual_save):\n",
        "  currentMax = 0\n",
        "  for r, _, f in os.walk(\"/content/Mangio-RVC-Fork/weights/\"):\n",
        "    for name in f:\n",
        "      if(name.endswith(\".pth\") and (name!=experiment_name+\".pth\")):\n",
        "        #Check to see if this PTH is what we're looking for.\n",
        "        if(name.find(experiment_name)==-1):\n",
        "          continue\n",
        "        #Determine Epochcount+Stepcount Phase 1\n",
        "        pot = name.split('_')\n",
        "        ep=pot[len(pot)-2][1:]\n",
        "        #If what we got from the epoch count section of the filename isn't a number, multiple completed models are in weights.\n",
        "        #Skip it if that happens.\n",
        "        if(not ep.isdecimal()):\n",
        "          continue\n",
        "        #Determine Epochcount+Stepcount Phase 2\n",
        "        ep=int(ep)\n",
        "        if ep>currentMax:\n",
        "          currentMax=ep\n",
        "          step=pot[len(pot)-1].split('.')\n",
        "          step=int(step[0][1:])\n",
        "          EPOCHCOUNT=ep\n",
        "          STEPCOUNT=step\n",
        "\n",
        "TSTEP = STEPCOUNT\n",
        "if(not skip_models):\n",
        "  print(\"Copying model files...\")\n",
        "  if(save_only_latest_ckpt):\n",
        "    TSTEP=2333333\n",
        "  !cp \"{DATASET_PATH_COLAB}/D_{TSTEP}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/G_{TSTEP}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/config.json\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"Copying Tensorboard TFEVENT files...\")\n",
        "for r, d, f in os.walk(DATASET_PATH_COLAB):\n",
        "  for name in f:\n",
        "    if(name.startswith(\"events.out.tfevents\") and os.path.exists(os.path.join(DATASET_PATH_COLAB, name))):\n",
        "      !cp \"{DATASET_PATH_COLAB}/{name}\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"Copying weight file...\")\n",
        "if(finished):\n",
        "  !cp \"{potential}\" \"{DATASET_PATH_DRIVE}\"\n",
        "else:\n",
        "  !cp \"/content/Mangio-RVC-Fork/weights/{experiment_name}_e{EPOCHCOUNT}_s{STEPCOUNT}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"All done!\")"
      ],
      "metadata": {
        "id": "HDsTxpbTqHol",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Export finished Model to HuggingFace\n",
        "#Credit to LollenApe for this cell!\n",
        "\n",
        "#TODO:\n",
        "#maybe remove glob dependency?\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "assert experiment_name, \"No experiment name found.\"\n",
        "\n",
        "#@markdown Use this option if you wish to manually use a specific epoch value. *Leave this blank if your model finished training.*\n",
        "manual_epoch_number = \"\" #@param {type:\"string\"}\n",
        "num_epochs = int(manual_epoch_number) if manual_epoch_number.isdigit() else None\n",
        "\n",
        "# Construct the weights path based on the provided number of epochs\n",
        "if num_epochs is not None:\n",
        "  weights_path = f\"/content/Mangio-RVC-Fork/weights/{experiment_name}_e{num_epochs}*\"\n",
        "else:\n",
        "  print(\"Autodetecting epoch count...\")\n",
        "  potential = f\"/content/Mangio-RVC-Fork/weights/{experiment_name}.pth\"\n",
        "  if os.path.exists(potential):\n",
        "    weights_path = f\"/content/Mangio-RVC-Fork/weights/{experiment_name}\"\n",
        "  else:\n",
        "    currentMax = 0\n",
        "    for r, _, f in os.walk(\"/content/Mangio-RVC-Fork/weights/\"):\n",
        "      for name in f:\n",
        "        if(name.endswith(\".pth\") and (name!=experiment_name+\".pth\")):\n",
        "          if(name.find(experiment_name)==-1):\n",
        "            continue\n",
        "          pot = name.split('_')\n",
        "          ep=pot[len(pot)-2][1:]\n",
        "          if(not ep.isdecimal()):\n",
        "            continue\n",
        "          ep=int(ep)\n",
        "          if ep>currentMax:\n",
        "            currentMax=ep\n",
        "    num_epochs=currentMax\n",
        "    weights_path = f\"/content/Mangio-RVC-Fork/weights/{experiment_name}_e{num_epochs}*\"\n",
        "  print(f\"Model with path {weights_path} found automatically.\")\n",
        "\n",
        "weights_files = glob.glob(weights_path + \".pth\")\n",
        "logs_path = f\"/content/Mangio-RVC-Fork/logs/{experiment_name}/added_*_1_{experiment_name}_{model_architecture}.index\"\n",
        "\n",
        "print(f\"Searching for weights files in: {weights_path}.pth\")\n",
        "print(f\"Searching for logs file in: {logs_path}\")\n",
        "\n",
        "if weights_files and any(glob_result := glob.glob(logs_path)):\n",
        "    log_file = glob_result[0]\n",
        "    output_folder = \"/content/toHF\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    output_zip_path = f\"{output_folder}/{experiment_name}.zip\"\n",
        "    with zipfile.ZipFile(output_zip_path, 'w') as zipf:\n",
        "        for weights_file in weights_files:\n",
        "            zipf.write(weights_file, os.path.basename(weights_file))\n",
        "        zipf.write(log_file, os.path.basename(log_file))\n",
        "    print(f\"The files have been added to the zip folder: {output_zip_path}\")\n",
        "else:\n",
        "    print(f\"Found weights files: {weights_files}\")\n",
        "    print(f\"Found logs files: {glob_result}\")\n",
        "    raise Exception(\"Couldn't find your model files. Check the found file results above. (Did you run Index Training?)\")\n",
        "\n",
        "from huggingface_hub import login, HfApi\n",
        "#@markdown Enter HuggingFace Token (set Role to 'write'):\n",
        "hftoken = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Login\n",
        "login(token=f\"{hftoken}\")\n",
        "\n",
        "#@markdown Set this option to true if you wish to create a new repository for this model.\n",
        "create_new_repo = False #@param {type:\"boolean\"}\n",
        "#@markdown Enter the HuggingFace repository name you wish to send the model to:\n",
        "repoid = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if create_new_repo:\n",
        "    from huggingface_hub import create_repo\n",
        "    create_repo(repoid)\n",
        "    print(f\"Repo '{repoid}' created successfully!\")\n",
        "\n",
        "api = HfApi()\n",
        "# Upload folders\n",
        "api.upload_folder(folder_path=\"/content/toHF\",\n",
        "                 repo_id=f\"{repoid}\",\n",
        "                 repo_type=\"model\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hiZmvKTOFLzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload your audo files to ```/content/Mangio-RVC-Fork/audios```"
      ],
      "metadata": {
        "id": "5KdujiOk1DiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO, Changelogs, Credits, and Special Thanks\n",
        "**TODO**\n",
        "*   Implement \"Export Lowest Points\", or implement [ROD](https://github.com/grvyscale/RealtimeOvertrainingDetection) on a seperate thread\n",
        "*   Implement 48k variant of the new RVCv2 pretrains when it is released\n",
        "*   Implement additions from [Sonphantrung's fork](https://colab.research.google.com/drive/1o4NbL2pCOkc6s5u_vyIReujwCetraTKb) into this notebook. (autosave, `f\"\"` formatting, preprocessing fusion, other things)\n",
        "\n",
        "**Changelogs**\n",
        "\n",
        "**v0.24** - Implemented SimplCup's Ov2Super new pretrains for 32k. Select `use_new_pretrains` to use it.\n",
        "\n",
        "**v0.23** - Implemented an option to use the new Ov2Super pretrained models by SimplCup. These will only work when training a v2 40k model.\n",
        "\n",
        "**v0.22** - Hopefully fixed an issue regarding people trying to install RVC twice. Also added a new cell to automatically send a model directly to Huggingface by LollenApe.\n",
        "\n",
        "Older changelogs can be found at https://rentry.co/rvcdisconnected_changelogs.\n",
        "\n",
        "**Credits**\n",
        "*   [MedicDoesStuff](https://www.youtube.com/@medicdoesstuff/) - modified this notebook\n",
        "*   [Kit Lemonfoot](https://huggingface.co/Kit-Lemonfoot) - writing this notebook\n",
        "*   [RVC Project](https://github.com/RVC-Project) - Created RVC, obviously\n",
        "*   [LJ1995](https://huggingface.co/lj1995) - Pretrained RVC models\n",
        "*   [Mangio261](https://github.com/Mangio621/) - Creating the Mangio RVC fork\n",
        "*   [Kalomaze](https://github.com/kalomaze) - Original RVC colab + Mangio tweaks\n",
        "*   [Alexlnkp](https://github.com/alexlnkp) - Created a more up-to-date variant of the Mangio-RVC fork\n",
        "*   [LollenApe](https://huggingface.co/lollenape) - Created the \"Export Finished Model to HuggingFace\" cell.\n",
        "*   [Pony Preservation Project](https://boards.4channel.org/mlp/catalog#s=Pony%20Preservation%20Project) - for their robust TalkNet and So-Vits-SVC notebooks\n",
        "*   the Colab team - forcing my hand and making me release this notebook early\n",
        "\n",
        "**Special Thanks**\n",
        "*   [Fifteen AI](https://15.ai/) - for getting me into voice AI in the first place\n",
        "*   [Dacoolkid44](https://huggingface.co/dacoolkid44) / [HoloAI44](https://www.youtube.com/@Holo_AI44) and Hijack / [SANSSWEEP](https://huggingface.co/SANSSWEEP) - for basically kickstarting the larger VTuber voice AI scene with their models\n",
        "*   [Maki Ligon](https://www.youtube.com/@Shiina_Mashiro) / [Yuuto Ichika](https://www.youtube.com/@yuutoichika) - for keeping me grounded in reality while developing this thing\n",
        "*   [Bartezes](https://www.youtube.com/@bartezes3082) - for helping me so much with the [VTuber AI Model Tracking spreadsheet](https://docs.google.com/spreadsheets/d/1tvZSggOsZGAPjbMrWOAAaoJJFpJuQlwUEQCf5x1ssO8/)\n",
        "*   [Megaaziib](https://www.youtube.com/@megaaziib) - for inspiring me to keep working on AI models and covers (I don't hate you)\n",
        "*   [Saintlysaint](https://www.youtube.com/@SaintlySaint) and [Gengar2525](https://www.youtube.com/@GeGaCh) - for having faith in me\n"
      ],
      "metadata": {
        "id": "g3fR68Yfkayg"
      }
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GnZdaTi6FgHf"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”´ **RVC - Disconnected** ðŸ”´\n",
        "\n",
        "***Modified by [MedicDoesStuff](https://www.youtube.com/@medicdoesstuff/)***\n",
        "\n",
        "**Notebook hastily written by [Kit Lemonfoot](https://huggingface.co/Kit-Lemonfoot) / [Noel Shirogane's High Flying Birds](https://www.youtube.com/@NoelShiroganesHighFlyingBirds)**\n",
        "\n",
        "*Based on the work of the [RVC Project](https://github.com/RVC-Project), [Mangio261](https://github.com/Mangio621/), [Kalomaze](https://github.com/kalomaze), [Alexlnkp](https://github.com/alexlnkp), the [Pony Preservation Project](https://boards.4channel.org/mlp/catalog#s=Pony%20Preservation%20Project), and many others in the RVC / voice AI community* â¤\n",
        "\n",
        "*Notebook version:* **0.24**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is designed to be used with training Retreival-Based Voice Conversion (RVC) models without using a WÐµbUl. This is done to stay within the scope of Colab's TOS.\n",
        "\n",
        "âš ï¸ WARNING: Unlike the original RVC notebook, *this notebook ***does not*** have autosave functionality* due to the massive amount of underlying stress that RVC's autosave features places on Colab to Drive communication. Please be careful and try to keep training sessions short."
      ],
      "metadata": {
        "id": "FrR4hoSR50Wt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dependencies**\n",
        "ðŸŸ¢ Run this first!"
      ],
      "metadata": {
        "id": "GnZdaTi6FgHf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBpJW3YB5zu1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install Dependencies\n",
        "import subprocess\n",
        "\n",
        "packages = ['build-essential', 'python3-dev', 'ffmpeg', 'aria2']\n",
        "pip_packages = ['pip', 'setuptools', 'wheel', 'httpx==0.23.0', 'faiss-gpu', 'fairseq', 'ffmpeg', 'ffmpeg-python', 'praat-parselmouth', 'pyworld', 'numpy==1.23.5', 'numba==0.56.4', 'librosa==0.9.2', 'gdown', 'onnxruntime', 'huggingface-hub']\n",
        "print(\"Updating and installing system packages...\")\n",
        "for package in packages:\n",
        "  print(f\"Installing {package}...\")\n",
        "  subprocess.check_call(['apt-get', 'install', '-qq', '-y', package])\n",
        "\n",
        "print(\"Updating and installing pip packages...\")\n",
        "subprocess.check_call(['pip', 'install', '--upgrade'] + pip_packages)\n",
        "\n",
        "print('Packages up to date.')\n",
        "firsttry = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Repositories\n",
        "import os\n",
        "\n",
        "# READ ME BEFORE CHANGING THINGS\n",
        "# If you're attempting to replace the imports here with Applio-RVC, it will not work due to requirement discrepancies across the entire notebook.\n",
        "# I will not be porting this notebook to Applio due to the failure of the Applio team to provide backwards compatibility with the Crepe and Mangio-Crepe f0 feature format.\n",
        "# DO NOT ASK. IT WILL NOT HAPPEN.\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "if(os.path.exists(\"/content/Mangio-RVC-Fork\")):\n",
        "  print(\"RVC already installed, skipping.\")\n",
        "else:\n",
        "  #Credit to miaaaa0a on the AI Hub Discord for (indirectly) suggesting this variant of Mangio RVC to me.\n",
        "  !git clone -b pr-optimization --single-branch https://github.com/alexlnkp/Mangio-RVC-Tweaks.git\n",
        "  #Rename to keep backwards compatibility with old variants of Disconnected\n",
        "  os.rename(\"/content/Mangio-RVC-Tweaks\", \"/content/Mangio-RVC-Fork\")\n",
        "  !git clone https://github.com/maxrmorrison/torchcrepe.git\n",
        "  !mv torchcrepe/torchcrepe Mangio-RVC-Fork/\n",
        "  !rm -rf torchcrepe  # Delete the torchcrepe repository folder\n",
        "  !wget -q https://cdn.discordapp.com/attachments/945486970883285045/1114717554481569802/peppy-generator-388800-07722f17a188.json -O /content/Mangio-RVC-Fork/peppy-generator-388800-07722f17a188.json\n",
        "\n",
        "os.chdir('/content/Mangio-RVC-Fork')\n",
        "now_dir = \"/content/Mangio-RVC-Fork\"\n",
        "os.makedirs(os.path.join(now_dir, \"logs\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(now_dir, \"weights\"), exist_ok=True)"
      ],
      "metadata": {
        "id": "McbFvkWfJQCO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Drive\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print('Drive is already mounted. Proceed.')\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/RVC-Disconnected', exist_ok=True)"
      ],
      "metadata": {
        "id": "1i1eYRMYfE79",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Pretrained Models\n",
        "#Didn't ask.\n",
        "\n",
        "#V1\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0G32k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0D32k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0G40k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0D40k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0G48k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0D48k.pth -d /content/Mangio-RVC-Fork/pretrained -o f0D48k.pth\n",
        "\n",
        "#V2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G32k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D32k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G40k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D40k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G48k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D48k.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D48k.pth\n",
        "\n",
        "#OV2 pretrains\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/f0Ov2Super32kG.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G32k_OV2.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/f0Ov2Super32kD.pth -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D32k_OV2.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super40kG.pth?download=true -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0G40k_OV2.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super40kD.pth?download=true -d /content/Mangio-RVC-Fork/pretrained_v2 -o f0D40k_OV2.pth\n",
        "\n",
        "#Hubert/RMVPE\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/hubert_base.pt -d /content/Mangio-RVC-Fork -o hubert_base.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/rmvpe.pt -d /content/Mangio-RVC-Fork -o rmvpe.pt\n",
        "\n",
        "#FM JSONs\n",
        "!rm -rf /content/Mangio-RVC-Fork/configs/32k.json\n",
        "!rm -rf /content/Mangio-RVC-Fork/configs/40k.json\n",
        "!rm -rf /content/Mangio-RVC-Fork/configs/48k.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/32k.json -d /content/Mangio-RVC-Fork/configs -o 32k.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/40k.json -d /content/Mangio-RVC-Fork/configs -o 40k.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/48k.json -d /content/Mangio-RVC-Fork/configs -o 48k.json"
      ],
      "metadata": {
        "id": "v_zQGeguKD5s",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup CSVDB\n",
        "#...Alright, you made your point.\n",
        "import csv\n",
        "\n",
        "if not os.path.isdir(\"csvdb/\"):\n",
        "  os.makedirs(\"csvdb\")\n",
        "  frmnt, stp = open(\"csvdb/formanting.csv\", \"w\", newline=\"\"), open(\"csvdb/stop.csv\", \"w\", newline=\"\")\n",
        "  csv_writer = csv.writer(frmnt, delimiter=\",\")\n",
        "  csv_writer.writerow([False, 1.0, 1.0])\n",
        "  csv_writer = csv.writer(stp, delimiter=\",\")\n",
        "  csv_writer.writerow([False])\n",
        "  frmnt.close()\n",
        "  stp.close()\n",
        "\n",
        "global DoFormant, Quefrency, Timbre\n",
        "DoFormant, Quefrency, Timbre = False, 1.0, 1.0"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0LGNhYjGaBBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set Training Variables**\n",
        "\n",
        "- `experiment_name`: The name of the model. (i.e: EminemMMLP2)\n",
        "- `model_architecture`: Specifies the chosen model version. V2 is recommended.\n",
        "- `target_sample_rate`: Specifies the desired sample rate for the model, The new 40K is recommended for general training.\n",
        "- `cpu_threads`: Specifies the number of CPU threads to be used during the training. Colab only has 2 so don't even bother changing it.\n",
        "- `speaker_id`: Represents the ID of the speaker being trained, I recommend not changing it.\n",
        "- `pitch_extraction_algorithm`: Specifies the algorithm used for pitch extraction from the audio data, rmvpe is recommended.\n",
        "- `crepe_hop_length`: Represents the hop length parameter used in the Crepe algorithm for pitch extraction, only affects crepe and mangio-crepe.\n",
        "- `pitch_guidance`: Indicates whether pitch guidance is enabled or disabled for the experiment, can be useful if you want a talking or singing model.\n",
        "- `use_new_pretrains`: Uses the new Ov2Super pretrained models."
      ],
      "metadata": {
        "id": "oi6yLWNM31rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set Training Variables\n",
        "now_dir = \"/content/Mangio-RVC-Fork\"\n",
        "experiment_name = \"experiment_name\" #@param {type:\"string\"}\n",
        "path_to_training_folder = \"/content/dataset/\"\n",
        "model_architecture = \"v2\" #@param [\"v1\",\"v2\"] {allow-input: false}\n",
        "target_sample_rate = \"40k\" #@param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n",
        "cpu_threads = 2 #@param {type:\"integer\"}\n",
        "speaker_id = 0 #@param {type:\"integer\"}\n",
        "pitch_extraction_algorithm = \"rmvpe\" #@param [\"harvest\", \"crepe\", \"mangio-crepe\", \"rmvpe\"] {allow-input: false}\n",
        "crepe_hop_length = 64 #@param {type:\"integer\"}\n",
        "pitch_guidance = True #@param {type:\"boolean\"}\n",
        "use_new_pretrains = True #@param {type:\"boolean\"}\n",
        "\n",
        "assert crepe_hop_length!=None, \"You need to input something for crepe_hop_length, silly.\"\n",
        "assert crepe_hop_length>0, \"Hop length must be more than 0.\"\n",
        "assert crepe_hop_length<=512, \"Save frequency must be less than 512.\"\n",
        "\n",
        "if use_new_pretrains:\n",
        "  assert model_architecture==\"v2\", \"The new pretrains are only for RVC v2. Please change your settings to match or use the old pretrains.\"\n",
        "  assert target_sample_rate!=\"48k\", \"The new pretrains are only for 32k and 40k at the moment. Please change your settings to match.\"\n",
        "\n",
        "if(experiment_name == \"experiment_name\"):\n",
        "  print(\"Warning: Your experiment name should be changed to the name of your dataset.\")"
      ],
      "metadata": {
        "id": "ZodNcumpg-JM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Preprocessing**\n",
        "ðŸŸ¢ You should only need to run these cells once per model."
      ],
      "metadata": {
        "id": "GpjFLdlRFlcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset\n",
        "#@markdown If it doesn't already exist, create a folder in your Google Drive named 'RVC-Disconnected' and place your zip file there. This will look for the following ZIP file inside that 'RVC-Disconnected' folder.\n",
        "dataset = \"zipfile.zip\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown This loader will load datasets in a similar fashion to the SVC dataset loader. For best results, your dataset should be formatted as such:\n",
        "#@markdown ```\n",
        "#@markdown zipfile.zip\n",
        "#@markdown â””â”€â”€â”€character_name\n",
        "#@markdown     â”œâ”€â”€â”€data.wav\n",
        "#@markdown ```\n",
        "#@markdown Audio filenames do not matter. All audio files should be in WAV format for best compatibility.\n",
        "\n",
        "#@markdown You do not need to split the WAV files, preprocessing will automatically do it for you.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "directories=[]\n",
        "\n",
        "def sanitize_directory(directory):\n",
        "  for filename in os.listdir(directory):\n",
        "    file_path = os.path.join(directory, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "      if filename == \".DS_Store\" or filename.startswith(\"._\") or not filename.endswith(('.wav', '.flac', '.mp3', '.ogg', '.m4a')):\n",
        "        os.remove(file_path)\n",
        "    elif os.path.isdir(file_path):\n",
        "      #Get rid of the MACOSX directory just so it doesn't mess with renaming later\n",
        "      if(filename == \"__MACOSX\"):\n",
        "        shutil.rmtree(file_path)\n",
        "        continue\n",
        "      #Append the directory to directories for future dataset check, then recurse.\n",
        "      directories.append(file_path)\n",
        "      sanitize_directory(file_path)\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/RVC-Disconnected/' + dataset\n",
        "final_directory = '/content/dataset'\n",
        "temp_directory = '/content/temp_dataset'\n",
        "\n",
        "if os.path.exists(final_directory):\n",
        "  print(\"Dataset folder already found. Wiping...\")\n",
        "  shutil.rmtree(final_directory)\n",
        "if os.path.exists(temp_directory):\n",
        "  print(\"Temporary folder already found. Wiping...\")\n",
        "  shutil.rmtree(temp_directory)\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "  raise Exception(f'I can\\'t find {dataset} in {os.path.dirname(dataset_path)}.')\n",
        "\n",
        "os.makedirs(final_directory, exist_ok=True)\n",
        "os.makedirs(temp_directory, exist_ok=True)\n",
        "#Oops.\n",
        "!unzip -d \"{temp_directory}\" -B \"{dataset_path}\"\n",
        "print(\"Sanitizing...\")\n",
        "sanitize_directory(temp_directory)\n",
        "\n",
        "if(len(directories) == 0):\n",
        "  #If there's no directories, we're dealing with a ZIP of just audio files.\n",
        "  #Move everything to /dataset/experiment_name/.\n",
        "  print(\"Dataset Type: Audio Files (Single Speaker)\")\n",
        "  expDir=os.path.join(final_directory, experiment_name)\n",
        "  os.makedirs(expDir, exist_ok=True)\n",
        "  for r, _, f in os.walk(temp_directory):\n",
        "    for name in f:\n",
        "      !cp \"{temp_directory}/{name}\" \"{expDir}\"\n",
        "elif(len(directories) == 1):\n",
        "  #If there's only one directory, we're dealing with a single speaker.\n",
        "  #Rename the folder to experiment_name and move it to /dataset/.\n",
        "  print(\"Dataset Type: Single Speaker\")\n",
        "  fi = os.path.join(temp_directory, experiment_name)\n",
        "  os.rename(directories[0], fi)\n",
        "  shutil.move(fi, final_directory)\n",
        "\n",
        "else:\n",
        "  #If anything else, we're dealing with multispeaker.\n",
        "  #Move all folders to /dataset/ indiscriminately.\n",
        "  print(\"Dataset Type: Multispeaker\")\n",
        "  for fi in directories:\n",
        "    shutil.move(fi, final_directory)\n",
        "\n",
        "shutil.rmtree(temp_directory)\n",
        "\n",
        "print(\"Dataset imported.\")\n"
      ],
      "metadata": {
        "id": "g1X5oANker6l",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocessing\n",
        "# Change the experiment Name and the path to the training folder. You shouldn't need to change anything else.\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "assert cpu_threads>0, \"CPU threads not allocated correctly.\"\n",
        "\n",
        "sr = int(target_sample_rate.rstrip('k'))*1000\n",
        "pttf = path_to_training_folder + experiment_name\n",
        "os.makedirs(\"%s/logs/%s\" % (now_dir, experiment_name), exist_ok=True)\n",
        "\n",
        "cmd = \"python trainset_preprocess_pipeline_print.py \\\"%s\\\" %s %s \\\"%s/logs/%s\\\" 1\" % (pttf, sr, cpu_threads, now_dir, experiment_name)\n",
        "print(cmd)\n",
        "!$cmd"
      ],
      "metadata": {
        "id": "OPNzuVYG7N_R",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature extraction\n",
        "\n",
        "pitch_extraction_algorithm = \"rmvpe\" #@param [\"harvest\", \"crepe\", \"mangio-crepe\", \"rmvpe\"] {allow-input: false}\n",
        "#crepe_hop_length = 128 #@param {type:\"slider\", min:1, max:512, step:1}\n",
        "#pitch_guidance = True #@param {type:\"boolean\"}\n",
        "\n",
        "gpuList = gpus.split(\"-\")\n",
        "cmd = \"python extract_f0_print.py \\\"%s/logs/%s\\\" %s %s %s\" % (now_dir, experiment_name, cpu_threads, pitch_extraction_algorithm, crepe_hop_length)\n",
        "print(cmd)\n",
        "!$cmd\n",
        "\n",
        "leng = len(gpus)\n",
        "\n",
        "cmd = \"python extract_feature_print.py %s %s %s %s \\\"%s/logs/%s\\\" %s\" % (\"device\", leng, 0, 0, now_dir, experiment_name, model_architecture)\n",
        "print(cmd)\n",
        "!$cmd\n"
      ],
      "metadata": {
        "id": "u6iN6C-U94DS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save preprocessed dataset files to Google Drive\n",
        "#Compress dataset folder\n",
        "loc = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
        "!zip -r rvcLogs.zip \"{loc}\"\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/RVC-Disconnected/\" + experiment_name\n",
        "!mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "!cp /content/Mangio-RVC-Fork/rvcLogs.zip \"{DATASET_PATH_DRIVE}\""
      ],
      "metadata": {
        "id": "y959_sq7kToW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**\n",
        "ðŸŸ¢ Also includes resuming code."
      ],
      "metadata": {
        "id": "vjcmh9u_MweU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load preprocessed dataset files from Google Drive (for resuming)\n",
        "#@markdown If you already have preprocessed dataset files on Google Drive, you can load them here instead of re-running the preprocessing steps.\n",
        "import os\n",
        "\n",
        "BACK_UP_DATASET_PATH = \"/content/drive/MyDrive/RVC-Disconnected/\" + experiment_name\n",
        "\n",
        "#Prevent people from loading the ZIP over existing files\n",
        "ok=True\n",
        "if(os.path.exists(\"/content/Mangio-RVC-Fork/logs/\"+experiment_name+\"/2a_f0\")):\n",
        "  print(\"Dataset files already loaded, skipping.\")\n",
        "  ok=False\n",
        "\n",
        "if ok:\n",
        "  !unzip \"{BACK_UP_DATASET_PATH}/rvcLogs.zip\" -d /"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_BkhWhrCMdgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Model from Drive to Notebook (for resuming)\n",
        "import os\n",
        "\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/RVC-Disconnected/\" + experiment_name\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "#@markdown Input the model's Step Count here (the number located on your model's G and D files.) If you used `save_only_last_ckpt` during training, this number will be 2333333.\n",
        "STEPCOUNT = 2333333 #@param {type:\"integer\"}\n",
        "\n",
        "print(\"Copying model files...\")\n",
        "!cp \"{DATASET_PATH_DRIVE}/D_{STEPCOUNT}.pth\" \"{DATASET_PATH_COLAB}\"\n",
        "!cp \"{DATASET_PATH_DRIVE}/G_{STEPCOUNT}.pth\" \"{DATASET_PATH_COLAB}\"\n",
        "!cp \"{DATASET_PATH_DRIVE}/config.json\" \"{DATASET_PATH_COLAB}\"\n",
        "\n",
        "print(\"Copying Tensorboard TFEVENT files...\")\n",
        "for r, _, f in os.walk(DATASET_PATH_DRIVE):\n",
        "  for name in f:\n",
        "    if(name.startswith(\"events.out.tfevents\")):\n",
        "      !cp \"{DATASET_PATH_DRIVE}/{name}\" \"{DATASET_PATH_COLAB}\"\n",
        "\n",
        "print(\"All done. Welcome back!\")"
      ],
      "metadata": {
        "id": "JbmAq_mZ7Zuh",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from random import shuffle\n",
        "\n",
        "# I will not be adding an autosave feature. Do not ask.\n",
        "\n",
        "#@title Training\n",
        "save_frequency = 50 #@param {type:\"integer\"}\n",
        "total_epochs = 300 #@param {type:\"integer\"}\n",
        "batch_size = 16 #@param {type:\"integer\"}\n",
        "save_only_latest_ckpt = True #@param {type:\"boolean\"}\n",
        "cache_all_training_sets = False #@param {type:\"boolean\"}\n",
        "save_small_final_model = True #@param {type:\"boolean\"}\n",
        "#@markdown The automatically calculated log interval is known to be very inaccurate and can cause delays between an epoch finishing and Tensorboard writes. If you would like, you can manually define a log interval here.\n",
        "use_manual_stepToEpoch = False #@param {type:\"boolean\"}\n",
        "manual_stepToEpoch = 000 #@param {type:\"integer\"}\n",
        "\n",
        "assert save_frequency!=None, \"You need to input something for save_frequency, silly.\"\n",
        "assert save_frequency>0, \"Save frequency must be more than 0.\"\n",
        "if(save_frequency>50):print(\"...A save frequency of %s? A bit high, but... alright then.\"%save_frequency)\n",
        "assert total_epochs!=None, \"You need to input something for total_epochs, silly.\"\n",
        "assert total_epochs>0, \"Total epochs must be more than 0.\"\n",
        "if(total_epochs>10000):print(\"...A total epoch count of of %s? This is going to overtrain, but... alright then.\"%total_epochs)\n",
        "assert batch_size!=None, \"You need to input something for batch_size, silly.\"\n",
        "assert batch_size>0, \"Batch size must be more than 0.\"\n",
        "assert batch_size<=40, \"Batch size must be less than 40. (I'd reccomend a value between 6 and 12 for Colab.)\"\n",
        "\n",
        "pretrained_base = \"pretrained/\" if model_architecture == \"v1\" else \"pretrained_v2/\"\n",
        "exp_dir = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
        "upt = \"_OV2\" if use_new_pretrains==True else \"\"\n",
        "\n",
        "pretrainedD = \"%sf0D%s%s.pth\" % (pretrained_base, target_sample_rate, upt)\n",
        "pretrainedG = \"%sf0G%s%s.pth\" % (pretrained_base, target_sample_rate, upt)\n",
        "\n",
        "#Log interval\n",
        "log_interval = 1\n",
        "liFolderPath = os.path.join(exp_dir, \"1_16k_wavs\")\n",
        "if(os.path.exists(liFolderPath) and os.path.isdir(liFolderPath)):\n",
        "  wav_files = [f for f in os.listdir(liFolderPath) if f.endswith(\".wav\")]\n",
        "  if wav_files:\n",
        "    sample_size = len(wav_files)\n",
        "    log_interval = math.ceil(sample_size / batch_size)\n",
        "    if log_interval > 1:\n",
        "      log_interval += 1\n",
        "\n",
        "if log_interval > 250 and not use_manual_stepToEpoch:\n",
        "  print(\"That's a big dataset you got there. Log interval normalized to 200 steps from %s steps.\" % log_interval)\n",
        "  log_interval = 200\n",
        "\n",
        "if use_manual_stepToEpoch:\n",
        "  log_interval = manual_stepToEpoch\n",
        "\n",
        "#Create Python command\n",
        "cmd = \"python train_nsf_sim_cache_sid_load_pretrain.py -e \\\"%s\\\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s -li %s\" % (\n",
        "    experiment_name,\n",
        "    target_sample_rate,\n",
        "    1,\n",
        "    batch_size,\n",
        "    0,\n",
        "    total_epochs,\n",
        "    save_frequency,\n",
        "    \"-pg %s\" % pretrainedG if pretrainedG != \"\" else \"\\b\",\n",
        "    \"-pd %s\" % pretrainedD if pretrainedD != \"\" else \"\\b\",\n",
        "    1 if save_only_latest_ckpt else 0,\n",
        "    1 if cache_all_training_sets else 0,\n",
        "    1 if save_small_final_model else 0,\n",
        "    model_architecture,\n",
        "    log_interval,\n",
        ")\n",
        "print(cmd)\n",
        "\n",
        "#Create mute filelist\n",
        "exp_dir = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
        "gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
        "feature_dir = (\n",
        "  \"%s/3_feature256\" % (exp_dir)\n",
        "  if model_architecture == \"v1\"\n",
        "  else \"%s/3_feature768\" % (exp_dir)\n",
        ")\n",
        "f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
        "f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
        "names = (\n",
        "  set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        ")\n",
        "opt = []\n",
        "for name in names:\n",
        "  opt.append(\n",
        "    \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "    % (\n",
        "      gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      speaker_id,\n",
        "    )\n",
        "  )\n",
        "fea_dim = 256 if model_architecture == \"v1\" else 768\n",
        "for _ in range(2):\n",
        "  opt.append(\n",
        "      \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
        "      % (now_dir, target_sample_rate, now_dir, fea_dim, now_dir, now_dir, speaker_id)\n",
        "  )\n",
        "shuffle(opt)\n",
        "with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
        "  f.write(\"\\n\".join(opt))\n",
        "print(\"Mute filelist written. Best of luck training!\")\n",
        "\n",
        "\n",
        "%cd /content/Mangio-RVC-Fork\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/Mangio-RVC-Fork/logs\n",
        "\n",
        "os.chdir('/content/Mangio-RVC-Fork')\n",
        "!$cmd\n"
      ],
      "metadata": {
        "id": "Yj-_npuA_HRB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Index Training\n",
        "#@markdown Ensure that Feature Extraction has run successfully before running this cell.\n",
        "\n",
        "#@markdown **Note: It's rare, but you may encounter a bug with this cell that requires a runtime restart.**\n",
        "#@markdown **If this happens, restart the runtime, re-run the \"Set Training Variables\" cell, then re-run this cell.**\n",
        "\n",
        "#@markdown Use this option if you wish to save the two extra files generated by index training to your Google Drive. (Only the added index is normally needed.)\n",
        "save_extra_files_to_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "#Oh dear lord why is this baked into infer-web I hate this\n",
        "import os\n",
        "import sys\n",
        "import traceback\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "#from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "exp_dir = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
        "os.makedirs(exp_dir, exist_ok=True)\n",
        "feature_dir = (\n",
        "    \"%s/3_feature256\" % (exp_dir)\n",
        "    if model_architecture == \"v1\"\n",
        "    else \"%s/3_feature768\" % (exp_dir)\n",
        ")\n",
        "print(feature_dir)\n",
        "if not os.path.exists(feature_dir):\n",
        "  raise Exception(\"No features exist for this model yet. Did you run Feature Extraction?\")\n",
        "listdir_res = list(os.listdir(feature_dir))\n",
        "if len(listdir_res) == 0:\n",
        "  raise Exception(\"No features exist for this model yet. Did you run Feature Extraction?\")\n",
        "\n",
        "try:\n",
        "  from sklearn.cluster import MiniBatchKMeans\n",
        "except:\n",
        "  print(\"Due to a bug with Colab, we will need to reinstall Numpy real quick. Give me a sec!\")\n",
        "  !pip install -U numpy\n",
        "  print(\"Numpy reinstalled. Please restart the runtime, and then re-run the \\\"Set Training Variables\\\" cell to continue.\")\n",
        "  sys.exit()\n",
        "else:\n",
        "  print(\"Proper Numpy version detected.\")\n",
        "\n",
        "infos=[]\n",
        "npys=[]\n",
        "for name in sorted(listdir_res):\n",
        "  phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
        "  npys.append(phone)\n",
        "big_npy = np.concatenate(npys, 0)\n",
        "big_npy_idx = np.arange(big_npy.shape[0])\n",
        "np.random.shuffle(big_npy_idx)\n",
        "if big_npy.shape[0] > 2e5:\n",
        "  print(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
        "  try:\n",
        "    big_npy = (\n",
        "        MiniBatchKMeans(\n",
        "            n_clusters=10000,\n",
        "            verbose=True,\n",
        "            batch_size=256,\n",
        "            compute_labels = False,\n",
        "            init=\"random\"\n",
        "        )\n",
        "        .fit(big_npy)\n",
        "        .cluster_centers_\n",
        "\n",
        "    )\n",
        "  except:\n",
        "    info = traceback.format_exc()\n",
        "    print(info)\n",
        "\n",
        "np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
        "n_ivf = min(int(16*np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "print(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
        "index = faiss.index_factory(256 if model_architecture == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
        "print(\"Training index...\")\n",
        "index_ivf = faiss.extract_index_ivf(index)\n",
        "index_ivf.nprobe = 1\n",
        "index.train(big_npy)\n",
        "faiss.write_index(\n",
        "    index,\n",
        "    \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\" % (exp_dir, n_ivf, index_ivf.nprobe, experiment_name, model_architecture)\n",
        ")\n",
        "print(\"Adding...\")\n",
        "batch_size_add = 8192\n",
        "for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "  index.add(big_npy[i:i+batch_size_add])\n",
        "faiss.write_index(\n",
        "    index,\n",
        "    \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "    % (exp_dir, n_ivf, index_ivf.nprobe, experiment_name, model_architecture)\n",
        ")\n",
        "\n",
        "npr = index_ivf.nprobe\n",
        "\n",
        "print(\"Saving files to Drive...\")\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/RVC-Disconnected/\" + experiment_name\n",
        "if(not os.path.exists(DATASET_PATH_DRIVE)):\n",
        "  !mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "if(save_extra_files_to_drive):\n",
        "  !cp \"{DATASET_PATH_COLAB}/total_fea.npy\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/trained_IVF{n_ivf}_Flat_nprobe_{npr}_{experiment_name}_{model_architecture}.index\" \"{DATASET_PATH_DRIVE}\"\n",
        "!cp \"{DATASET_PATH_COLAB}/added_IVF{n_ivf}_Flat_nprobe_{npr}_{experiment_name}_{model_architecture}.index\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"All done! Your index file has completed training.\")\n",
        "try:\n",
        "  firsttry\n",
        "except:\n",
        "  print(\"If you had to restart the runtime, disconnect and delete the runtime in order to continue. (Restarting the runtime again will not work.)\")\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9mI_m7vfimC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Export Model from Notebook to Drive\n",
        "import os\n",
        "\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/RVC-Disconnected/\" + experiment_name\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "if(not os.path.exists(DATASET_PATH_DRIVE)):\n",
        "  !mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "#@markdown Use this option if you wish to only copy over weights.\n",
        "skip_models = False #@param {type:\"boolean\"}\n",
        "#@markdown Use these options if you wish to manually input your step count and epoch count for incomplete models. *Do not use this option if your training finished.*\n",
        "manual_save = False #@param {type:\"boolean\"}\n",
        "STEPCOUNT = 000 #@param {type:\"integer\"}\n",
        "EPOCHCOUNT = 000 #@param {type:\"integer\"}\n",
        "\n",
        "finished=False\n",
        "potential=\"/content/Mangio-RVC-Fork/weights/\"+experiment_name+\".pth\"\n",
        "if os.path.exists(potential):\n",
        "  finished = True\n",
        "\n",
        "#VERY hacky. Might break stuff, report to me if it does.\n",
        "print(\"Detecting latest model...\")\n",
        "if(not manual_save):\n",
        "  currentMax = 0\n",
        "  for r, _, f in os.walk(\"/content/Mangio-RVC-Fork/weights/\"):\n",
        "    for name in f:\n",
        "      if(name.endswith(\".pth\") and (name!=experiment_name+\".pth\")):\n",
        "        #Check to see if this PTH is what we're looking for.\n",
        "        if(name.find(experiment_name)==-1):\n",
        "          continue\n",
        "        #Determine Epochcount+Stepcount Phase 1\n",
        "        pot = name.split('_')\n",
        "        ep=pot[len(pot)-2][1:]\n",
        "        #If what we got from the epoch count section of the filename isn't a number, multiple completed models are in weights.\n",
        "        #Skip it if that happens.\n",
        "        if(not ep.isdecimal()):\n",
        "          continue\n",
        "        #Determine Epochcount+Stepcount Phase 2\n",
        "        ep=int(ep)\n",
        "        if ep>currentMax:\n",
        "          currentMax=ep\n",
        "          step=pot[len(pot)-1].split('.')\n",
        "          step=int(step[0][1:])\n",
        "          EPOCHCOUNT=ep\n",
        "          STEPCOUNT=step\n",
        "\n",
        "TSTEP = STEPCOUNT\n",
        "if(not skip_models):\n",
        "  print(\"Copying model files...\")\n",
        "  if(save_only_latest_ckpt):\n",
        "    TSTEP=2333333\n",
        "  !cp \"{DATASET_PATH_COLAB}/D_{TSTEP}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/G_{TSTEP}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/config.json\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"Copying Tensorboard TFEVENT files...\")\n",
        "for r, d, f in os.walk(DATASET_PATH_COLAB):\n",
        "  for name in f:\n",
        "    if(name.startswith(\"events.out.tfevents\") and os.path.exists(os.path.join(DATASET_PATH_COLAB, name))):\n",
        "      !cp \"{DATASET_PATH_COLAB}/{name}\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"Copying weight file...\")\n",
        "if(finished):\n",
        "  !cp \"{potential}\" \"{DATASET_PATH_DRIVE}\"\n",
        "else:\n",
        "  !cp \"/content/Mangio-RVC-Fork/weights/{experiment_name}_e{EPOCHCOUNT}_s{STEPCOUNT}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"All done!\")"
      ],
      "metadata": {
        "id": "HDsTxpbTqHol",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Export finished Model to HuggingFace\n",
        "#Credit to LollenApe for this cell!\n",
        "\n",
        "#TODO:\n",
        "#maybe remove glob dependency?\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "\n",
        "assert experiment_name, \"No experiment name found.\"\n",
        "\n",
        "#@markdown Use this option if you wish to manually use a specific epoch value. *Leave this blank if your model finished training.*\n",
        "manual_epoch_number = \"\" #@param {type:\"string\"}\n",
        "num_epochs = int(manual_epoch_number) if manual_epoch_number.isdigit() else None\n",
        "\n",
        "# Construct the weights path based on the provided number of epochs\n",
        "if num_epochs is not None:\n",
        "  weights_path = f\"/content/Mangio-RVC-Fork/weights/{experiment_name}_e{num_epochs}*\"\n",
        "else:\n",
        "  print(\"Autodetecting epoch count...\")\n",
        "  potential = f\"/content/Mangio-RVC-Fork/weights/{experiment_name}.pth\"\n",
        "  if os.path.exists(potential):\n",
        "    weights_path = f\"/content/Mangio-RVC-Fork/weights/{experiment_name}\"\n",
        "  else:\n",
        "    currentMax = 0\n",
        "    for r, _, f in os.walk(\"/content/Mangio-RVC-Fork/weights/\"):\n",
        "      for name in f:\n",
        "        if(name.endswith(\".pth\") and (name!=experiment_name+\".pth\")):\n",
        "          if(name.find(experiment_name)==-1):\n",
        "            continue\n",
        "          pot = name.split('_')\n",
        "          ep=pot[len(pot)-2][1:]\n",
        "          if(not ep.isdecimal()):\n",
        "            continue\n",
        "          ep=int(ep)\n",
        "          if ep>currentMax:\n",
        "            currentMax=ep\n",
        "    num_epochs=currentMax\n",
        "    weights_path = f\"/content/Mangio-RVC-Fork/weights/{experiment_name}_e{num_epochs}*\"\n",
        "  print(f\"Model with path {weights_path} found automatically.\")\n",
        "\n",
        "weights_files = glob.glob(weights_path + \".pth\")\n",
        "logs_path = f\"/content/Mangio-RVC-Fork/logs/{experiment_name}/added_*_1_{experiment_name}_{model_architecture}.index\"\n",
        "\n",
        "print(f\"Searching for weights files in: {weights_path}.pth\")\n",
        "print(f\"Searching for logs file in: {logs_path}\")\n",
        "\n",
        "if weights_files and any(glob_result := glob.glob(logs_path)):\n",
        "    log_file = glob_result[0]\n",
        "    output_folder = \"/content/toHF\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    output_zip_path = f\"{output_folder}/{experiment_name}.zip\"\n",
        "    with zipfile.ZipFile(output_zip_path, 'w') as zipf:\n",
        "        for weights_file in weights_files:\n",
        "            zipf.write(weights_file, os.path.basename(weights_file))\n",
        "        zipf.write(log_file, os.path.basename(log_file))\n",
        "    print(f\"The files have been added to the zip folder: {output_zip_path}\")\n",
        "else:\n",
        "    print(f\"Found weights files: {weights_files}\")\n",
        "    print(f\"Found logs files: {glob_result}\")\n",
        "    raise Exception(\"Couldn't find your model files. Check the found file results above. (Did you run Index Training?)\")\n",
        "\n",
        "from huggingface_hub import login, HfApi\n",
        "#@markdown Enter HuggingFace Token (set Role to 'write'):\n",
        "hftoken = \"Obtain this at https://huggingface.co/settings/tokens\" #@param {type:\"string\"}\n",
        "\n",
        "# Login\n",
        "login(token=f\"{hftoken}\")\n",
        "\n",
        "#@markdown Set this option to true if you wish to create a new repository for this model.\n",
        "create_new_repo = False #@param {type:\"boolean\"}\n",
        "#@markdown Enter the HuggingFace repository name you wish to send the model to:\n",
        "repoid = \"username/RepoName\" #@param {type:\"string\"}\n",
        "\n",
        "if create_new_repo:\n",
        "    from huggingface_hub import create_repo\n",
        "    create_repo(repoid)\n",
        "    print(f\"Repo '{repoid}' created successfully!\")\n",
        "\n",
        "api = HfApi()\n",
        "# Upload folders\n",
        "api.upload_folder(folder_path=\"/content/toHF\",\n",
        "                 repo_id=f\"{repoid}\",\n",
        "                 repo_type=\"model\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hiZmvKTOFLzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference (EXPERIMENTAL)**"
      ],
      "metadata": {
        "id": "dYy3qmsjpkC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Step 2. Download The Model\n",
        "#@markdown Link the URL path to the model (Mega, Drive, etc.) and start the code\n",
        "\n",
        "from mega import Mega\n",
        "import os\n",
        "import shutil\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import urllib.parse\n",
        "from google.oauth2.service_account import Credentials\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import hashlib\n",
        "\n",
        "def calculate_md5(file_path):\n",
        "    hash_md5 = hashlib.md5()\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "            hash_md5.update(chunk)\n",
        "    return hash_md5.hexdigest()\n",
        "config_path = '/content/RVC-Disconnected/peppy-generator-388800-07722f17a188.json'\n",
        "\n",
        "condition1 = False\n",
        "condition2 = False\n",
        "already_downloaded = False\n",
        "\n",
        "# condition1 here is to check if the .index was imported. 2 is for if the .pth was.\n",
        "\n",
        "!rm -rf /content/unzips/\n",
        "!rm -rf /content/zips/\n",
        "!mkdir /content/unzips\n",
        "!mkdir /content/zips\n",
        "\n",
        "def sanitize_directory(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            if filename == \".DS_Store\" or filename.startswith(\"._\"):\n",
        "                os.remove(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            sanitize_directory(file_path)\n",
        "\n",
        "url = 'https://huggingface.co/medicreal/MedicAI/resolve/main/EminemMMLP2.zip'  #@param {type:\"string\"}\n",
        "model_zip = urlparse(url).path.split('/')[-2] + '.zip'\n",
        "model_zip_path = '/content/zips/' + model_zip\n",
        "\n",
        "#private_model = False #@param{type:\"boolean\"}\n",
        "\n",
        "if url != '':\n",
        "    MODEL = \"\"  # Initialize MODEL variable\n",
        "    !mkdir -p /content/RVC-Disconnected/logs/$MODEL\n",
        "    !mkdir -p /content/zips/\n",
        "    !mkdir -p /content/RVC-Disconnected/weights/  # Create the 'weights' directory\n",
        "\n",
        "    if \"drive.google.com\" in url:\n",
        "        !gdown $url --fuzzy -O \"$model_zip_path\"\n",
        "    elif \"/blob/\" in url:\n",
        "        url = url.replace(\"blob\", \"resolve\")\n",
        "        print(\"Resolved URL:\", url)  # Print the resolved URL\n",
        "        !wget \"$url\" -O \"$model_zip_path\"\n",
        "    elif \"mega.nz\" in url:\n",
        "        m = Mega()\n",
        "        print(\"Starting download from MEGA....\")\n",
        "        m.download_url(url, '/content/zips')\n",
        "    elif \"/tree/main\" in url:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        temp_url = ''\n",
        "        for link in soup.find_all('a', href=True):\n",
        "            if link['href'].endswith('.zip'):\n",
        "                temp_url = link['href']\n",
        "                break\n",
        "        if temp_url:\n",
        "            url = temp_url\n",
        "            print(\"Updated URL:\", url)  # Print the updated URL\n",
        "            url = url.replace(\"blob\", \"resolve\")\n",
        "            print(\"Resolved URL:\", url)  # Print the resolved URL\n",
        "\n",
        "            if \"huggingface.co\" not in url:\n",
        "                url = \"https://huggingface.co\" + url\n",
        "\n",
        "            !wget \"$url\" -O \"$model_zip_path\"\n",
        "        else:\n",
        "            print(\"No .zip file found on the page.\")\n",
        "            # Handle the case when no .zip file is found\n",
        "    else:\n",
        "        !wget -q \"$url\" -O \"$model_zip_path\"\n",
        "\n",
        "    for filename in os.listdir(\"/content/zips\"):\n",
        "        if filename.endswith(\".zip\"):\n",
        "            zip_file = os.path.join(\"/content/zips\", filename)\n",
        "            shutil.unpack_archive(zip_file, \"/content/unzips\", 'zip')\n",
        "\n",
        "sanitize_directory(\"/content/unzips\")\n",
        "\n",
        "def find_pth_file(folder):\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for file in files:\n",
        "            if file.endswith(\".pth\"):\n",
        "                file_name = os.path.splitext(file)[0]\n",
        "                if file_name.startswith(\"G_\") or file_name.startswith(\"P_\"):\n",
        "                    config_file = os.path.join(root, \"config.json\")\n",
        "                    if os.path.isfile(config_file):\n",
        "                        print(\"Outdated .pth detected! This is not compatible with the RVC method. Find the RVC equivalent model!\")\n",
        "                    continue  # Continue searching for a valid file\n",
        "                file_path = os.path.join(root, file)\n",
        "                if os.path.getsize(file_path) > 100 * 1024 * 1024:  # Check file size in bytes (100MB)\n",
        "                    print(\"Skipping unusable training file:\", file)\n",
        "                    continue  # Continue searching for a valid file\n",
        "                return file_name\n",
        "    return None\n",
        "\n",
        "MODEL = find_pth_file(\"/content/unzips\")\n",
        "if MODEL is not None:\n",
        "    print(\"Found .pth file:\", MODEL + \".pth\")\n",
        "else:\n",
        "    print(\"Error: Could not find a valid .pth file within the extracted zip.\")\n",
        "    print(\"If there's an error above this talking about 'Access denied', try one of the Alt URLs in the Google Sheets for this model.\")\n",
        "    MODEL = \"\"\n",
        "    global condition3\n",
        "    condition3 = True\n",
        "\n",
        "index_path = \"\"\n",
        "\n",
        "def find_version_number(index_path):\n",
        "    if condition2 and not condition1:\n",
        "        if file_size >= 55180000:\n",
        "            return 'RVC v2'\n",
        "        else:\n",
        "            return 'RVC v1'\n",
        "\n",
        "    filename = os.path.basename(index_path)\n",
        "\n",
        "    if filename.endswith(\"_v2.index\"):\n",
        "        return 'RVC v2'\n",
        "    elif filename.endswith(\"_v1.index\"):\n",
        "        return 'RVC v1'\n",
        "    else:\n",
        "        if file_size >= 55180000:\n",
        "            return 'RVC v2'\n",
        "        else:\n",
        "            return 'RVC v1'\n",
        "\n",
        "if MODEL != \"\":\n",
        "    # Move model into logs folder\n",
        "    for root, dirs, files in os.walk('/content/unzips'):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if file.endswith(\".index\"):\n",
        "                print(\"Found index file:\", file)\n",
        "                condition1 = True\n",
        "                logs_folder = os.path.join('/content/RVC-Disconnected/logs', MODEL)\n",
        "                os.makedirs(logs_folder, exist_ok=True)  # Create the logs folder if it doesn't exist\n",
        "\n",
        "                # Delete identical .index file if it exists\n",
        "                if file.endswith(\".index\"):\n",
        "                    identical_index_path = os.path.join(logs_folder, file)\n",
        "                    if os.path.exists(identical_index_path):\n",
        "                        os.remove(identical_index_path)\n",
        "\n",
        "                shutil.move(file_path, logs_folder)\n",
        "                index_path = os.path.join(logs_folder, file)  # Set index_path variable\n",
        "\n",
        "            elif \"G_\" not in file and \"D_\" not in file and file.endswith(\".pth\"):\n",
        "                destination_path = f'/content/RVC-Disconnected/weights/{MODEL}.pth'\n",
        "                if os.path.exists(destination_path):\n",
        "                    print(\"You already downloaded this model. Re-importing anyways..\")\n",
        "                    already_downloaded = True\n",
        "                shutil.move(file_path, destination_path)\n",
        "                condition2 = True\n",
        "                if already_downloaded is False and os.path.exists(config_path):\n",
        "                    file_size = os.path.getsize(destination_path) # Get file size\n",
        "                    md5_hash = calculate_md5(destination_path) # Calculate md5 hash\n",
        "                    index_version = find_version_number(index_path)  # Get the index version\n",
        "\n",
        "if condition1 is False:\n",
        "    logs_folder = os.path.join('/content/RVC-Disconnected/logs', MODEL)\n",
        "    os.makedirs(logs_folder, exist_ok=True)\n",
        "# this is here so it doesnt crash if the model is missing an index for some reason\n",
        "\n",
        "if condition2 and not condition1:\n",
        "    print(\"Model partially imported! No .index file was found in the model download. The author may have forgotten to add the index file.\")\n",
        "    if already_downloaded is False and os.path.exists(config_path) and not private_model:\n",
        "        update_sheet(url, MODEL, file_size, md5_hash, index_version)\n",
        "\n",
        "elif condition1 and condition2:\n",
        "    print(\"Model successfully imported!\")\n",
        "    if already_downloaded is False and os.path.exists(config_path) and not private_model:\n",
        "        update_sheet(url, MODEL, file_size, md5_hash, index_version)\n",
        "\n",
        "elif condition3:\n",
        "    pass  # Do nothing when condition3 is true\n",
        "else:\n",
        "    print(\"URL cannot be left empty. If you don't want to download a model now, just skip this step.\")\n",
        "\n",
        "!rm -r /content/unzips/\n",
        "!rm -r /content/zips/"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3xB1HLQhq8Rf",
        "outputId": "1a7c55ad-61c9-44b0-b151-c22607f71c6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found .pth file: model.pth\n",
            "You already downloaded this model. Re-importing anyways..\n",
            "Found index file: model.index\n",
            "Model successfully imported!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload your audo files to ```/content/Mangio-RVC-Fork/audios```"
      ],
      "metadata": {
        "id": "5KdujiOk1DiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Run inference (Using CLI)\n",
        "\n",
        "!python infer-web.py --pycmd python --is_cli\n",
        "\n",
        "#@markdown This uses the Gradio CLI, allowing you to run inference using your own models. Please note that this feature is experimental.\n",
        "\n",
        "#@markdown **Instructions:**\n",
        "\n",
        "#@markdown **1.** Run the cell.\n",
        "\n",
        "#@markdown **2.** Type ```go infer```.\n",
        "\n",
        "#@markdown **3.** Copy the following format:\n",
        "\n",
        "#@markdown ```\n",
        "#@markdown modelname.pth audios/input.wav output.wav logs/[modelname]/added_IVF574_Flat_nprobe_1_modelname_v2.index 0 0 rmvpe 160 3 0 0.75 0.7 0.33 0.45 False 8.0 1.2\n",
        "#@markdown ```\n",
        "\n",
        "#@markdown Once done, you can download the WAV file from ```/content/Mangio-RVC-Fork/audio-outputs``` in the left file browser."
      ],
      "metadata": {
        "cellView": "form",
        "id": "MczsozZ9vUGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO, Changelogs, Credits, and Special Thanks\n",
        "**TODO**\n",
        "*   Implement \"Export Lowest Points\", or implement [ROD](https://github.com/grvyscale/RealtimeOvertrainingDetection) on a seperate thread\n",
        "*   Implement 48k variant of the new RVCv2 pretrains when it is released\n",
        "*   Implement additions from [Sonphantrung's fork](https://colab.research.google.com/drive/1o4NbL2pCOkc6s5u_vyIReujwCetraTKb) into this notebook. (autosave, `f\"\"` formatting, preprocessing fusion, other things)\n",
        "\n",
        "**Changelogs**\n",
        "\n",
        "**v0.24** - Implemented SimplCup's Ov2Super new pretrains for 32k. Select `use_new_pretrains` to use it.\n",
        "\n",
        "**v0.23** - Implemented an option to use the new Ov2Super pretrained models by SimplCup. These will only work when training a v2 40k model.\n",
        "\n",
        "**v0.22** - Hopefully fixed an issue regarding people trying to install RVC twice. Also added a new cell to automatically send a model directly to Huggingface by LollenApe.\n",
        "\n",
        "Older changelogs can be found at https://rentry.co/RVC-Disconnected_changelogs.\n",
        "\n",
        "**Credits**\n",
        "*   [MedicDoesStuff](https://www.youtube.com/@medicdoesstuff/) - modified this notebook\n",
        "*   [Kit Lemonfoot](https://huggingface.co/Kit-Lemonfoot) - writing this notebook\n",
        "*   [RVC Project](https://github.com/RVC-Project) - Created RVC, obviously\n",
        "*   [LJ1995](https://huggingface.co/lj1995) - Pretrained RVC models\n",
        "*   [Mangio261](https://github.com/Mangio621/) - Creating the Mangio RVC fork\n",
        "*   [Kalomaze](https://github.com/kalomaze) - Original RVC colab + Mangio tweaks\n",
        "*   [Alexlnkp](https://github.com/alexlnkp) - Created a more up-to-date variant of the Mangio-RVC fork\n",
        "*   [LollenApe](https://huggingface.co/lollenape) - Created the \"Export Finished Model to HuggingFace\" cell.\n",
        "*   [Pony Preservation Project](https://boards.4channel.org/mlp/catalog#s=Pony%20Preservation%20Project) - for their robust TalkNet and So-Vits-SVC notebooks\n",
        "*   the Colab team - forcing my hand and making me release this notebook early\n",
        "\n",
        "**Special Thanks**\n",
        "*   [Fifteen AI](https://15.ai/) - for getting me into voice AI in the first place\n",
        "*   [Dacoolkid44](https://huggingface.co/dacoolkid44) / [HoloAI44](https://www.youtube.com/@Holo_AI44) and Hijack / [SANSSWEEP](https://huggingface.co/SANSSWEEP) - for basically kickstarting the larger VTuber voice AI scene with their models\n",
        "*   [Maki Ligon](https://www.youtube.com/@Shiina_Mashiro) / [Yuuto Ichika](https://www.youtube.com/@yuutoichika) - for keeping me grounded in reality while developing this thing\n",
        "*   [Bartezes](https://www.youtube.com/@bartezes3082) - for helping me so much with the [VTuber AI Model Tracking spreadsheet](https://docs.google.com/spreadsheets/d/1tvZSggOsZGAPjbMrWOAAaoJJFpJuQlwUEQCf5x1ssO8/)\n",
        "*   [Megaaziib](https://www.youtube.com/@megaaziib) - for inspiring me to keep working on AI models and covers (I don't hate you)\n",
        "*   [Saintlysaint](https://www.youtube.com/@SaintlySaint) and [Gengar2525](https://www.youtube.com/@GeGaCh) - for having faith in me\n"
      ],
      "metadata": {
        "id": "g3fR68Yfkayg"
      }
    }
  ]
}